{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile={'max_input_tokens': 128000, 'max_output_tokens': 16384, 'image_inputs': True, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True, 'structured_output': True, 'image_url_inputs': True, 'pdf_inputs': True, 'pdf_tool_message': True, 'image_tool_message': True, 'tool_choice': True} client=<openai.resources.chat.completions.completions.Completions object at 0x0000022C506F78B0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022C506F6470> root_client=<openai.OpenAI object at 0x0000022C506F6DA0> root_async_client=<openai.AsyncOpenAI object at 0x0000022C506F6500> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provide some inputs and get response from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence that focuses on creating new content, such as images, text, music, and videos. It leverages models and algorithms, particularly deep learning techniques, to generate data that is similar to the existing data it was trained on, while also allowing for novel outputs. Some of the most common approaches within generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These consist of two neural networks—the generator and the discriminator—that are trained together. The generator creates fake data with the aim of fooling the discriminator, which attempts to distinguish between real and generated data. This adversarial process improves the quality of the generated outputs over time.\\n\\n2. **Variational Autoencoders (VAEs):** VAEs are a type of neural network used for generating new data by learning the probability distribution of the input data. They encode data into a latent space and then decode it to create new output that is consistent with the original input distribution.\\n\\n3. **Transformer Models:** These models, such as GPT (Generative Pre-trained Transformer) developed by OpenAI, are particularly influential in natural language processing. They generate text by predicting the next word in a sentence given the previous words, using large-scale training on extensive text corpora. They are also being adapted for modalities beyond text, such as images (e.g., DALL-E, Stable Diffusion).\\n\\nGenerative AI has numerous applications, including content creation for media and entertainment, design and art, automated code generation, and virtual environments for simulations and gaming. It also poses challenges and ethical considerations, particularly in regards to authenticity, copyright issues, and the potential for misuse.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 339, 'prompt_tokens': 13, 'total_tokens': 352, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e413f45763', 'id': 'chatcmpl-Cnpu9hE9OjbE98UkATz9Vvg04sr6M', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b2d6c-4893-72c3-a14e-8e69070c0068-0' usage_metadata={'input_tokens': 13, 'output_tokens': 339, 'total_tokens': 352, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the project on LangChain (LangSmith) go the path:\n",
    "https://smith.langchain.com/o/214cdbbd-3d25-40cb-93ba-b7b3e35d7f2c/projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatPrompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"You are an expert AI Engineer. Provide me answers based on the question\"),\n",
    "     (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a platform designed to enhance the development and management of AI applications, especially those built with natural language processing (NLP) capabilities. Its key features focus on improving the interaction and performance of language models, such as those used in chatbots and other AI-driven tools. Langsmith provides developers with tools to debug, test, evaluate, and monitor these applications in real time. It offers capabilities like intelligent string interpolation, conversation analytics, and seamless model integration, which help in identifying and addressing issues early in the development phase and maintaining optimal performance in production. The platform aims to streamline the process of building language-centric AI applications by offering a comprehensive suite of tools for continuous improvement and deployment.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 33, 'total_tokens': 171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_e413f45763', 'id': 'chatcmpl-Cnq7xVhnqW1fN8bcnK1Ktx4UYn5qO', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019b2d79-5568-7920-baa1-c7104195e8d0-0' usage_metadata={'input_tokens': 33, 'output_tokens': 138, 'total_tokens': 171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# first it will get the prompt then llm and combine them\n",
    "chain = prompt|llm \n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a platform developed by LangChain that aids developers in building applications powered by large language models (LLMs). It offers a suite of tools designed to enhance the development and debugging processes for LLM-based applications. With Langsmith, developers can efficiently track, evaluate, and improve their applications by utilizing features such as dataset management, analytics, and tracing. These capabilities help in understanding the performance of language models, optimizing their outputs, and addressing any potential issues that arise during the development lifecycle. Additionally, Langsmith integrates seamlessly with the broader LangChain ecosystem, providing a comprehensive solution for those working with LLMs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chain = prompt | llm | output_parser`\n",
    "\n",
    "The `|` symbol means:\n",
    "Take the output from the left and pass it as input to the right\n",
    "\n",
    "1. Prompt:\n",
    "{\"input\": \"Can you tell me about Langsmith?\"}\n",
    "↓\n",
    "\"Can you tell me about Langsmith?\"\n",
    "\n",
    "2. | llm:\n",
    "Prompt string\n",
    "↓\n",
    "AIMessage(content=\"LangSmith is ...\")\n",
    "\n",
    "3. | output_parser:\n",
    "AIMessage(content=\"LangSmith is ...\")\n",
    "↓\n",
    "\"LangSmith is ...\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
